# -*- coding: utf-8 -*-
"""00_intro_to_TF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CFPRCTBpTbKBXkIRXhQnVI3LTWsEMczl
"""

import tensorflow as tf
# Regression Modeling
import numpy as np
import matplotlib.pyplot as plt 
#x = np.arange(-20,20,3)
#y = np.arange(20,60,3)
x = np.arange(-100,100,2)
y = (x*2)+5
#y = np.arange(-100,100,20)
x = tf.constant(x)
y = tf.constant(y)
plt.scatter(x,y)


##########################

x_train = x[:80]
y_train = y[:80]

x_test = x[80:]
y_test = y[80:]
print(len(x_train), len(y_train), len(x_test), len(y_test))

plt.figure(figsize = (10,7))
plt.scatter(x_train,y_train, c="g", label = "Training Data")
plt.scatter(x_test,y_test, c="r", label = "Testing Data")
plt.legend()

#Creating model that builds automatically by defining input 
#shape argument

tf.random.set_seed(42)
#defining
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, input_shape = [1], name = "input_Layer"), #because we have input shape 1t
    #tf.keras.layers.Dense(100, activation=None, name = "input_layer2"),
    #tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(1, name = "Output_layer")
], name = "My_First_Practice_Model") 

#compiling
model.compile(loss="mae",
             optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
              #optimizer=tf.keras.optimizers.SGD(),
             metrics=["mae"])

#fitting the model
model.fit(x_train,y_train,epochs=100, verbose = 0)
# verbose = 0 will make output not to show up

#below command shows the info about model parameters
model.summary()

#pictorial dipiction
from tensorflow.keras.utils import plot_model

plot_model(model = model, show_shapes=True )

#pridiction on the basis of test sets

y_pred = model.predict(x_test)
print(y_pred)
print(y_test)



#plotting function to compare y_pred and y_test

def plotpred(train_data = x_train, train_labels = y_train,
             test_data = x_test, test_labels = y_test,
             predictions = y_pred):
  ### Ploting
  plt.figure(figsize=(7,7))
  plt.scatter(train_data, train_labels, c='r', label="Training_data")
  plt.scatter(test_data, test_labels, c='b', label="Testing_data")
  plt.scatter(test_data, predictions, c='g', label="Predictions")
  plt.legend()

  
plotpred()

#Evaluation of our prediction with regression evaluation metrics
#our two main metrices so far are: mae and mse (mean absolute and mean sqauare error)
# MAE --> on avg, how wrong is each of the model's prediction is
# MSE --> squares the avg errors

model.evaluate(x_test, y_test)

#func for calculating mae 
#tf.keras.losses.MAE(y_test, y_pred)
#tf.metrics.mean_absolute_error(y_true = y_test, y_pred = y_pred )
# use tf.squeeze(y_pred) for reshaping or changing dimention
def mae_cal(y_test, y_pred):
  return tf.metrics.mean_absolute_error(y_true = y_test, y_pred = tf.squeeze(y_pred))

#Now mean squared error
def mse_cal(y_test, y_pred):
  return tf.metrics.mean_squared_error(y_true = y_test, y_pred = tf.squeeze(y_pred))

# Now Building different models by changing dense layers, epochs and optimizers
#and finally visualize and compare predictions
import pandas as pd

#Model1 --> 1 Dense layer, SGD optimizer, 100 epochs

tf.random.set_seed(42)
#defining
model1 = tf.keras.Sequential([
    tf.keras.layers.Dense(1)
], name = "First_Practice_Model") 

#compiling
model1.compile(loss="mae",
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

#fitting the model
model1.fit(x_train,y_train,epochs=100, verbose = 0)

y_pred1 = model1.predict(x_test)

#ploting
plotpred(x_train,y_train,
         x_test,y_test,
         y_pred1)
#Error calculations
mae1 = mae_cal(y_test, y_pred1)
mse1 = mse_cal(y_test, y_pred1)
mae1, mse1

#Model2 --> 2 Dense layers, SGD optimizer, 200 epochs

tf.random.set_seed(42)
#defining
model2 = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation=None),
    tf.keras.layers.Dense(1)
], name = "Second_Practice_Model") 

#compiling
model2.compile(loss="mae",
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

#fitting the model
model2.fit(x_train,y_train,epochs=200, verbose = 0)

y_pred2 = model2.predict(x_test)

#ploting
plotpred(x_train,y_train,
         x_test,y_test,
         y_pred2)
#Error calculations
mae2 = mae_cal(y_test, y_pred2)
mse2 = mse_cal(y_test, y_pred2)

mae2, mse2

#Model3 --> 2 Dense layers, adam optimizer, 200 epochs

tf.random.set_seed(42)
#defining
model3 = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation=None),
    tf.keras.layers.Dense(1)
], name = "Third_Practice_Model") 

#compiling
model3.compile(loss="mae",
              optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),
              metrics=["mae"])

#fitting the model
model3.fit(x_train,y_train,epochs=200, verbose = 0)

y_pred3 = model3.predict(x_test)

#ploting
plotpred(x_train,y_train,
         x_test,y_test,
         y_pred3)
#Error calculations
mae3 = mae_cal(y_test, y_pred3)
mse3 = mse_cal(y_test, y_pred3)
mae3, mse3

#Now compare models' results usinf pandas Dataframe

model_results = [["Model_1", mae1.numpy(), mse1.numpy()],
                 ["Model_2", mae2.numpy(), mse2.numpy()],
                 ["Model_3", mae3.numpy(), mse3.numpy()]]

all_resuts = pd.DataFrame(model_results, columns = ["Model", "mae", "mse"])
all_resuts